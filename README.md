# 聊天记录分析工具

本项目是一个基于 Python 的聊天记录分析工具，能够处理中文聊天记录，对聊天内容进行清洗、分词、词频统计、情感分析，并生成多种可视化图表。该工具支持对单个或多个聊天记录文件进行处理，并提供对不同聊天记录情感指数的对比分析。

## 主要功能

1. **数据清洗**：去除聊天记录中的空格、表情符号和图片标识，并将时间字段转换为标准日期格式。
2. **分词处理**：使用 `jieba` 库对聊天内容进行分词，并过滤掉常见的停用词。
3. **词频统计**：统计每个词语在聊天记录中的出现频率，并生成高频词汇的可视化图表（词云和柱状图）。
4. **情感分析**：使用 `SnowNLP` 对每条消息进行情感分析，得出每条消息的情感得分（0 到 1 之间，越接近 1 表示情感越正面）。
5. **可视化展示**：
   - 每日总消息量趋势图。
   - 每个发言者的发言频率趋势图。
   - 词云图和词频前 20 的词条柱状图。
   - 每日情感变化趋势图和情感得分分布图。
6. **多文件支持**：支持处理多个聊天记录文件，合并后进行分析。
7. **情感对比分析**：在多个聊天记录中，对比不同来源的情感均值、情感峰值及每日情感趋势，并生成图表展示。

## 项目依赖

该项目使用了以下 Python 库：

- `pandas`：用于数据处理和分析。
- `jieba`：用于中文分词。
- `re`：用于正则表达式清理文本。
- `collections.Counter`：用于词频统计。
- `snownlp`：用于中文文本的情感分析。
- `matplotlib`：用于生成图表。
- `wordcloud`：用于生成词云。

可以通过以下命令安装所需依赖：

```bash
pip install pandas jieba snownlp matplotlib wordcloud
```

## 使用说明

### 1. 前期准备

可以参考这个项目：https://github.com/BlueMatthew/WechatExporter
按照这一项目的说明，导出聊天记录为txt文档；

### 2. 处理数据

将txt文档转换为符合以下格式的 CSV 文件：

- **必需的列**：
  - `DateTime`：表示消息发送的时间。
  - `Speaker`：表示消息发送者。
  - `Message`：表示消息内容。

示例 CSV 文件格式：

| DateTime            | Speaker | Message     |
|---------------------|---------|-------------|
| 2023-01-01 08:00:00 | Alice   | 早上好！     |
| 2023-01-01 08:05:00 | Bob     | [表情]       |
| 2023-01-01 08:10:00 | Alice   | 今天的天气真好！ |
| 2023-01-01 08:15:00 | Bob     | 是啊，阳光明媚。 |

可以使用convert_txt_to_csv.py 这一文件进行转换；
```bash
python convert_txt_to_csv.py
```

### 3. 运行程序

运行主程序，通过输入 CSV 文件的路径开始分析。程序支持单个文件和多个文件的输入。

运行以下命令：

```bash
python message_ana.py
```

## 案例展示
![image](https://github.com/user-attachments/assets/77e97cf4-1ad8-485b-b0d2-40a4e658fc63)
![image](https://github.com/user-attachments/assets/f2e0fa60-3c86-42df-90fe-28e7d1a0fbdf)
![image](https://github.com/user-attachments/assets/b5c34fd0-f024-4d3b-b3df-276d1158e46d)
<img width="530" alt="image" src="https://github.com/user-attachments/assets/5f845c19-c6c8-4d16-afbf-02d7c64bb5e2">
<img width="529" alt="image" src="https://github.com/user-attachments/assets/ba68e3af-ef98-4141-b8f0-4ca130cdf043">

您在 GitHub 项目 [message-analysis](https://github.com/Dorian-wei/message-analysis) 中添加了群聊年度报告功能，建议在 `README.md` 中更新以下内容：


# 新增功能：群聊年度报告生成

这是一个基于 Python 和 Streamlit 的工具，用于分析群聊数据并生成全面的年度报告。报告包含消息总量、活跃发言者、年度热词、表情包统计、情感分析和群聊活跃度等内容。

---

## 功能概述

1. **数据清洗**：
   - 自动去除表情符号、图片占位符等无关内容。
   - 转换时间格式，确保数据一致性。

2. **年度总结**：
   - 总消息数、总字数统计。
   - 最早和最晚的消息及其发言者和时间。

3. **活跃发言者排行**：
   - 按发言条数和字数对发言者进行排名，有小彩蛋哦～

4. **年度热词统计**：
   - 自动提取群聊中的关键词，列出出现次数最多的前 5 个热词。

5. **表情包统计**：
   - 动态统计年度使用频率最高的表情。

6. **情感分析**：
   - 利用 `SnowNLP` 分析情感趋势，展示正负面情绪变化。

7. **可视化图表**：
   - 年度词云图
   - 活跃度热力图
   - 群聊情绪雷达图

---

## 使用方法

### 1. 准备运行环境
确保 Python 环境中已安装以下依赖库：
```bash
pip install pandas jieba snownlp streamlit wordcloud seaborn
```

### 2. 准备聊天数据文件
将聊天记录保存为 CSV 格式，文件需包含以下列：
- `DateTime`: 消息的时间，格式为 `YYYY-MM-DD HH:MM:SS`。
- `Speaker`: 发言者姓名。
- `Message`: 消息内容。

示例：
```csv
DateTime,Speaker,Message
2023-01-01 12:00:00,张三,大家新年好！[微笑]
2023-01-01 12:01:00,李四,新年快乐！[旺柴]
2023-01-01 12:02:00,王五,哈哈哈，开心！[呲牙]
```

### 3. 运行程序
将代码保存为 `wechat_annual_report.py`，在终端中运行：
```bash
streamlit run wechat_annual_report.py
```

### 4. 上传聊天记录
在打开的网页界面中，上传聊天记录 CSV 文件，工具将自动生成年度报告。

---

## 生成内容

### 年度总结
包括：
- 总消息量、总字数。
- 最早和最晚消息的发言者、时间和内容。

### 活跃发言者
列出年度发言最多的前 3 名成员及其字数统计。

### 年度热词
展示出现频率最高的 5 个关键词及其出现次数。

### 表情包统计
提取并展示年度使用最多的表情包 Top 5。

### 可视化图表
1. **词云图**：基于年度热词生成。
2. **热力图**：按日期和时间展示活跃度。
3. **情感趋势图**：展示正负面情感的变化趋势。
4. **情绪雷达图**：总结年度整体情绪分布。

---

## 注意事项

1. **CSV 格式要求**：
   - 确保列名为 `DateTime`、`Speaker` 和 `Message`，否则会报错。

2. **中文字体支持**：
   - 如果图表中的中文无法正常显示，需安装中文字体并设置路径。

3. **停用词调整**：
   - 根据需求，修改代码中的 `stopwords` 列表，以优化关键词提取结果。

4. **情感分析**：
   - 使用 `SnowNLP` 进行情感分析，适用于中文内容。

---

## 示例输出

**年度总结**
```
📊 群聊【xxxx】2023年度报告
🪩 在这一年中，我们在群里一共发出了 23628 条消息，累计打下了 229153 个字。
🌙 最晚的一条消息是由 [张三] 在 2023-08-06 02:45:55 发送的，内容是：
> 卧槽
```

**活跃发言者**
```
🥇 张三 - 发言 7623 条，累计 73673 个字
🥈 李四 - 发言 5221 条，累计 42636 个字
🥉 王五 - 发言 4590 条，累计 45317 个字
```

**年度热词**
```
1. 哈哈哈 - 出现了 575 次
2. offer - 出现了 318 次
3. 面试 - 出现了 315 次
4. 确实 - 出现了 313 次
5. 开心 - 出现了 308 次
```

**年度表情包**
```
1. [微笑] - 使用了 120 次
2. [流泪] - 使用了 98 次
3. [旺柴] - 使用了 75 次
4. [破涕为笑] - 使用了 50 次
5. [呲牙] - 使用了 30 次
```

---

## 常见问题

1. **上传文件后没有生成报告？**
   - 检查 CSV 文件格式是否正确，列名是否与代码匹配。

2. **词云图不显示中文？**
   - 确保系统安装了中文字体并在代码中设置字体路径。

3. **情感分析结果偏差？**
   - `SnowNLP` 的情感分析适用于大多数中文场景，但可能不适用于特殊语言表达。
